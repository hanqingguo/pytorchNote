{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central to all neural networks in PyTorch is the __autograd__ package.\n",
    "\n",
    "__autograd.Variable__ is something can be updated and auto grad, like W and b in neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "require_grad = True means this variable require backward, so b.grad_fn is an object, otherwise,\n",
    "b.grad_fn is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>) <AddBackward object at 0x7f903f171940>\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>) grad of b is <AddBackward object at 0x7f903f1719b0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2,requires_grad=True)\n",
    "print(a)\n",
    "b = a + 2\n",
    "print(b, b.grad_fn)\n",
    "\n",
    "a1 = torch.ones(2,2,requires_grad=True)\n",
    "b1 = a1 + 2\n",
    "print(b, \"grad of b is {}\".format(b1.grad_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Variable.backward() to compute the derivation of the Variable\n",
    "\n",
    "Here __b, c, out__ are all variable\n",
    "\n",
    ".backward() can be used because out is scala.\n",
    "\n",
    "运行这个 使得神经网络 从此处开始回传， 将此参数一直往前求导\n",
    "\n",
    "例如下例：\n",
    "\n",
    "If Variable is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to backward(), however if it has more elements, you need to specify a gradient argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "c = b*b*3\n",
    "out = c.mean()\n",
    "print(c,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run __out.backward()__ will get each deraviation of out\n",
    "\n",
    "$\\frac{\\partial out}{\\partial c}$,\n",
    "$\\frac{\\partial out}{\\partial b}$,\n",
    "$\\frac{\\partial out}{\\partial a}$,\n",
    "\n",
    "### when run a.grad or b.grad or c.grad, it should gives the result of \n",
    "$\\frac{\\partial out}{\\partial a}$  or  $\\frac{\\partial out}{\\partial b}$ or $\\frac{\\partial out}{\\partial c}$,\n",
    "\n",
    "but as link below says:\n",
    "\n",
    "### hook media https://discuss.pytorch.org/t/why-cant-i-see-grad-of-an-intermediate-variable/94\n",
    "gradients are only retained for leaf variables. non-leaf variables’ gradients are not retained to be inspected later. This was done by design, to save memory.\n",
    "\n",
    "So you can not get b.grad and c.grad by default.\n",
    "\n",
    "But we can use hook to get this:\n",
    "\n",
    "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
    "*Variable* “$o$”.\n",
    "We have that $o = \\frac{1}{4}\\sum_i c_i$,\n",
    "$c_i = 3(a_i+2)^2$ and $c_i\\bigr\\rvert_{a_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial a_i} = \\frac{3}{2}(a_i+2)$, hence\n",
    "\n",
    "here, a1, a2, a3, a4 =1\n",
    "$\\frac{\\partial o}{\\partial a_i}\\bigr\\rvert_{a_i=1} = \\frac{9}{2} = 4.5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.grad still be Variable!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But when run b.grad, c.grad then them is None.\n",
    "### Because pytorch only retain gradients of leaf variable to save memory, say \n",
    "b = a + 1\n",
    "\n",
    "c = $b * b * 3$\n",
    "\n",
    "out = c.mean()\n",
    "\n",
    "### only a is leaf variable. If we need inter-variable gradient, we need to use hook as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(b.grad, c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.]])\n",
      "tensor([[18.]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "xx = torch.ones(1,1,requires_grad = True)\n",
    "yy = 3*xx\n",
    "zz = yy**2\n",
    "\n",
    "yy.register_hook(print)\n",
    "\n",
    "zz.backward()\n",
    "print(xx.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two more things!\n",
    "#### 1. When run .backward twice, it will give error, since when the graph back ward compute complete, they delete intermediate result, if you want to run it again, need to initial Variable again\n",
    "#### 2. If you didn't clear gradient of one variable, then run .backward() again, in former example, run out.backward() again, then x.grad will increase to 9!\n",
    "\n",
    "### Important!!\n",
    "#### In previous example, only scala can use .backward()\n",
    "#### actually, every Variable can use that, but need to pass in a tensor to make sure which part and relative weight for this part you selected to compute gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4., 6., 8.]], grad_fn=<MulBackward>) tensor([20.], grad_fn=<SumBackward1>)\n",
      "tensor([[2., 0., 0., 0.]])\n",
      "tensor([[0., 2., 0., 0.]])\n",
      "tensor([[2., 2., 2., 2.]])\n",
      "tensor([[2., 2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1., 2., 3., 4.]], requires_grad=True)\n",
    "z = 2*x\n",
    "loss = z.sum(dim=1)\n",
    "print(z, loss)\n",
    "\n",
    "# do backward for first element of z\n",
    "z.backward(torch.FloatTensor([[1, 0, 0, 0]]))\n",
    "print(x.grad.data)\n",
    "x.grad.data.zero_() #remove gradient in x.grad, or it will be accumulated\n",
    "\n",
    "# do backward for second element of z\n",
    "z.backward(torch.FloatTensor([[0, 1, 0, 0]]))\n",
    "print(x.grad.data)\n",
    "x.grad.data.zero_()\n",
    "\n",
    "# do backward for all elements of z, with weight equal to the derivative of\n",
    "# loss w.r.t z_1, z_2, z_3 and z_4\n",
    "z.backward(torch.FloatTensor([[1, 1, 1, 1]]))\n",
    "print(x.grad.data)\n",
    "x.grad.data.zero_()\n",
    "\n",
    "# or we can directly backprop using loss\n",
    "loss.backward() # equivalent to loss.backward(torch.FloatTensor([1.0]))\n",
    "print(x.grad.data)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
