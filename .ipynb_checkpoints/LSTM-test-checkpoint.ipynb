{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [torch.randn(1, 5) for _ in range(4)]  # make a sequence of length 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are __4__ inputs, each input has __5__ features, so LSTM __input dim = 5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.9922,  0.7802, -0.6727,  1.9629, -0.1278]]),\n",
       " tensor([[ 0.2803,  0.5734,  1.4915, -0.6404, -1.5168]]),\n",
       " tensor([[ 0.2716, -0.9033, -1.8071, -0.5176, -0.0370]]),\n",
       " tensor([[-0.4774, -0.5221,  0.4505,  0.3980,  0.0160]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = torch.cat(inputs).view(len(inputs),1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.9922,  0.7802, -0.6727,  1.9629, -0.1278]],\n",
       " \n",
       "         [[ 0.2803,  0.5734,  1.4915, -0.6404, -1.5168]],\n",
       " \n",
       "         [[ 0.2716, -0.9033, -1.8071, -0.5176, -0.0370]],\n",
       " \n",
       "         [[-0.4774, -0.5221,  0.4505,  0.3980,  0.0160]]]),\n",
       " torch.Size([4, 1, 5]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape, reshape.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 is hidden_size, is hidden state dim.\n",
    "\n",
    "In this case, \n",
    "\n",
    "for each second, \n",
    "\n",
    "### xt.shape = (features, 1) => (5, 1)\n",
    "\n",
    "### yt.shape = (features, 1) => (5, 1)\n",
    "\n",
    "### ht.shape = (hidden_size, 1) => (3 ,1) \n",
    "\n",
    "### whh.shape = (hidden_size, hidden_size) =>(3,3)\n",
    "\n",
    "### wxh.shape = (hidden_size, features) => (3,5)\n",
    "\n",
    "### why.shape = (features, hidden_size) => (5,3)\n",
    "\n",
    "下图$g_{t}$ 和 $\\tilde{C_{t}}$ 一样。\n",
    "input_size is features\n",
    "\n",
    "para0 : [24,10] = 4*hidden_size, input_size\n",
    "\n",
    "$W_{ii}, W_{if},W_{ig},W_{io}$\n",
    "\n",
    "para1 : [24,6] = 4*hidden_size, hidden_size\n",
    "$W_{hi}, W_{hf},W_{hg},W_{ho}$\n",
    "\n",
    "para2 : [24] = 4*hidden_size\n",
    "$b_{ii}, b_{if},b_{ig},b_{io}$\n",
    "\n",
    "para3 : [24] = 4*hidden_size\n",
    "$b_{hi}, b_{hf},b_{hg},b_{ho}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([24, 10])\n",
      "1 torch.Size([24, 6])\n",
      "2 torch.Size([24])\n",
      "3 torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "lstm1 = nn.LSTM(input_size = 10, hidden_size = 6)\n",
    "for i, para in enumerate(lstm1.parameters()):\n",
    "    print(i, para.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For each element in the input sequence, each layer computes the following function__\n",
    "\n",
    "\\begin{split}\\begin{array}{ll}\n",
    "i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n",
    "c_t = f_t c_{(t-1)} + i_t g_t \\\\\n",
    "h_t = o_t \\tanh(c_t)\n",
    "\\end{array}\\end{split}\n",
    "\n",
    "![1.png](lstm-img/lstm1.png)\n",
    "![2.png](lstm-img/lstm2.png)\n",
    "![3.png](lstm-img/lstm3.png)\n",
    "![4.png](lstm-img/lstm4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(5,3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __input_size__ – The number of expected features in the input x\n",
    "* __hidden_size__ – The number of features in the hidden state h\n",
    "* __num_layers__ – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1 \n",
    "\n",
    "(__this is how many layers stack upper together__)\n",
    "\n",
    "* __bias__ – If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "* __batch_first__ – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False\n",
    "* __dropout__ – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "* __bidirectional__ – If True, becomes a bidirectional LSTM. Default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step1: initialize hidden\n",
    "hidden is tuple, \n",
    "(h0,c0)\n",
    "In this case, both h_0 and c_0 are (2,1,3)\n",
    "\n",
    "                                    (\n",
    "                                    \n",
    "                                     2  => lstm_num_layer * num_directions \n",
    "                                     1  => mini-batch_size,\n",
    "                                     3  => hidden_size\n",
    "                                     \n",
    "                                     )\n",
    "__num_direction__ is 1 by default (when bidirectional is False)\n",
    "\n",
    "__num_direction__ is 2 (when bidirectional is True)\n",
    "\n",
    "thanks answer from https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks#/media/File:RNN_BRNN.png\n",
    "\n",
    "https://discuss.pytorch.org/t/what-is-num-directions-of-nn-lstm/11663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = (torch.randn(2, 1, 3),\n",
    "          torch.randn(2, 1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step2: construct input\n",
    "input of lstm is (4,1,5)\n",
    "\n",
    "                 (\n",
    "                 \n",
    "                  4 => sequence_num,\n",
    "                  1 => mini-batch_size,\n",
    "                  5 => features number for every time\n",
    "                  \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.cat(inputs).view(len(inputs),1,-1)\n",
    "input1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before inputs is:\n",
      " [tensor([[ 0.6622,  1.6556,  0.6693, -0.8457,  0.8894]]), tensor([[-0.6806,  0.5081, -0.4722, -1.0739,  0.9023]]), tensor([[ 0.7480,  0.8019, -0.2547,  0.0481,  1.5207]]), tensor([[-0.2853, -1.1381, -0.9574, -0.8077,  0.1744]])]\n",
      "\n",
      "before length of inputs is: 4\n",
      "\n",
      "after input1 is:\n",
      " tensor([[[ 0.6622,  1.6556,  0.6693, -0.8457,  0.8894]],\n",
      "\n",
      "        [[-0.6806,  0.5081, -0.4722, -1.0739,  0.9023]],\n",
      "\n",
      "        [[ 0.7480,  0.8019, -0.2547,  0.0481,  1.5207]],\n",
      "\n",
      "        [[-0.2853, -1.1381, -0.9574, -0.8077,  0.1744]]])\n",
      "\n",
      "after input1.size is: torch.Size([4, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"before inputs is:\\n {}\\n\\n\"\n",
    "      \"before length of inputs is: {}\\n\\n\"\n",
    "      \"after input1 is:\\n {}\\n\\n\"\n",
    "      \"after input1.size is: {}\".format(inputs, len(inputs), input1, input1.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input of lstm is:\n",
    "\n",
    "__input1, (h0, c0)__\n",
    "\n",
    "### Output of lstm is:\n",
    "\n",
    "__output, (hn, cn)__\n",
    "\n",
    "\n",
    "#### If input is only one step of a sequence, then ouput is\n",
    "\n",
    "__output__ of lstm is (1,1,3)\n",
    "\n",
    "                 (\n",
    "                \n",
    "                  1 => sequence_num,\n",
    "                  1 => mini-batch_size,\n",
    "                  3 => num_directions * hidden_size\n",
    "                  \n",
    "                 )\n",
    "              \n",
    "__num_direction__ is 1 by default (when bidirectional is False)\n",
    "\n",
    "__num_direction__ is 2 (when bidirectional is True)\n",
    "\n",
    "output __hidden__ is __h_n__, __c_n__,\n",
    "\n",
    "both of them have shape of (2,1,3)\n",
    "\n",
    "                                (\n",
    "\n",
    "                                 2  => lstm_num_layer * num_directions \n",
    "                                 1  => mini-batch_size,\n",
    "                                 3  => hidden_size\n",
    "\n",
    "                                 )\n",
    "                                 \n",
    "the last slice of __h_n__, is equal to __out__\n",
    "\n",
    "hidden[0][1,:,:] == out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out is:\n",
      "tensor([[[ 0.1718, -0.1224, -0.1719]]])\n",
      " out.shape is:\n",
      "torch.Size([1, 1, 3])\n",
      "\n",
      "\n",
      "h_n is:\n",
      "tensor([[[ 0.0776,  0.0843,  0.2449]],\n",
      "\n",
      "        [[ 0.1718, -0.1224, -0.1719]]])\n",
      "\n",
      ", h_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "c_n is:\n",
      "tensor([[[ 0.4472,  0.2617,  0.5426]],\n",
      "\n",
      "        [[ 0.6434, -0.2376, -0.3676]]])\n",
      "\n",
      ", c_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "\n",
      "out is:\n",
      "tensor([[[ 0.1687, -0.1234, -0.1716]]])\n",
      " out.shape is:\n",
      "torch.Size([1, 1, 3])\n",
      "\n",
      "\n",
      "h_n is:\n",
      "tensor([[[ 0.0863,  0.1179,  0.3284]],\n",
      "\n",
      "        [[ 0.1687, -0.1234, -0.1716]]])\n",
      "\n",
      ", h_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "c_n is:\n",
      "tensor([[[ 0.3224,  0.3522,  0.5558]],\n",
      "\n",
      "        [[ 0.6452, -0.2376, -0.3670]]])\n",
      "\n",
      ", c_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "\n",
      "out is:\n",
      "tensor([[[ 0.1711, -0.1238, -0.1735]]])\n",
      " out.shape is:\n",
      "torch.Size([1, 1, 3])\n",
      "\n",
      "\n",
      "h_n is:\n",
      "tensor([[[ 0.0935,  0.1233,  0.3011]],\n",
      "\n",
      "        [[ 0.1711, -0.1238, -0.1735]]])\n",
      "\n",
      ", h_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "c_n is:\n",
      "tensor([[[ 0.3851,  0.5083,  0.4121]],\n",
      "\n",
      "        [[ 0.6501, -0.2374, -0.3724]]])\n",
      "\n",
      ", c_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "\n",
      "out is:\n",
      "tensor([[[ 0.1663, -0.1315, -0.1607]]])\n",
      " out.shape is:\n",
      "torch.Size([1, 1, 3])\n",
      "\n",
      "\n",
      "h_n is:\n",
      "tensor([[[ 0.0333,  0.1868,  0.4579]],\n",
      "\n",
      "        [[ 0.1663, -0.1315, -0.1607]]])\n",
      "\n",
      ", h_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "c_n is:\n",
      "tensor([[[ 0.0916,  0.3811,  0.6277]],\n",
      "\n",
      "        [[ 0.6592, -0.2553, -0.3400]]])\n",
      "\n",
      ", c_n shape is:\n",
      "torch.Size([2, 1, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    # hidden is a tuple\n",
    "    print(\"out is:\\n{}\\n out.shape is:\\n{}\\n\\n\".format(out, out.size()))\n",
    "    print(\"h_n is:\\n{}\\n\\n, h_n shape is:\\n{}\\n\"\n",
    "           \"c_n is:\\n{}\\n\\n, c_n shape is:\\n{}\\n\".format(hidden[0],hidden[0].size(), hidden[1], hidden[1].size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If input is whole sequence, then ouput is\n",
    "\n",
    "__output__ of lstm is (4,1,3)\n",
    "\n",
    "                 (\n",
    "                \n",
    "                  4 => sequence_num,\n",
    "                  1 => mini-batch_size,\n",
    "                  3 => num_directions * hidden_size\n",
    "                  \n",
    "                 )\n",
    "\n",
    "output __hidden__ is __h_n__, __c_n__,\n",
    "\n",
    "both of them have shape of (2,1,3)\n",
    "\n",
    "                                (\n",
    "\n",
    "                                 2  => lstm_num_layer * num_directions \n",
    "                                 1  => mini-batch_size,\n",
    "                                 3  => hidden_size\n",
    "\n",
    "                                 )\n",
    "                                 \n",
    "The last slice of __out__ is equal to last slice __h_n__\n",
    "\n",
    "out[3,:,:] == hidden[0][1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0840,  0.0881, -0.5538]],\n",
      "\n",
      "        [[ 0.2312,  0.0122, -0.2594]],\n",
      "\n",
      "        [[ 0.1971, -0.0598, -0.2299]],\n",
      "\n",
      "        [[ 0.1827, -0.0999, -0.1956]]]) torch.Size([4, 1, 3])\n",
      "(tensor([[[ 0.0360,  0.1725,  0.3835]],\n",
      "\n",
      "        [[ 0.1827, -0.0999, -0.1956]]]), tensor([[[ 0.1035,  0.3549,  0.5074]],\n",
      "\n",
      "        [[ 0.7407, -0.1862, -0.4313]]]))\n",
      "tensor([[ 0.1827, -0.0999, -0.1956]])\n",
      "tensor([[ 0.1827, -0.0999, -0.1956]])\n"
     ]
    }
   ],
   "source": [
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "\n",
    "# out[3,:,:] is same as hidden[0][1,:,:]\n",
    "\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "hidden = (torch.randn(2, 1, 3), torch.randn(2, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(input1, hidden)\n",
    "print(out, out.size())\n",
    "\n",
    "print(hidden)\n",
    "\n",
    "print(out[3,:,:])\n",
    "print(hidden[0][1,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
